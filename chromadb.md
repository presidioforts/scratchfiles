### Is “**Summary + RAG content + citations**” a sound, standard pattern?

Yes — it’s the norm for production RAG assistants used by GitHub Copilot, Perplexity AI, Bing Copilot, and most enterprise chatbots:

1. **Summary** – a 2-to-4-sentence direct answer generated by the LLM.
2. **Context / RAG payload** – the exact passages (or full docs) that fed the model.
3. **Inline citations** – each claim in the summary is tagged \[#1], \[#2] and maps to a context chunk.

This balances **speed** (answer comes first), **trust** (users can audit every claim), and **depth-on-demand** (they read the raw doc only if needed). So your understanding is correct and industry-standard.

---

## How to emit all three pieces from your existing `orchestrator.py`

```python
# orchestrator.py  (only the changed bits)

@app.post("/ask")
async def ask(req: AskReq):
    # 1) Retrieve
    r = await client.post(RAG_URL, json={"query": req.question, "k": TOP_K})
    r.raise_for_status()
    payload = r.json()
    docs  = payload["docs"]          # chunk text
    metas = payload.get("meta", [])  # filenames, URLs, etc.

    # 2) Build prompt (unchanged) … call LLM … get `summary`
    summary = g.json()["text"]

    # 3) Pack full response
    snippets = [
        {
            "id": idx + 1,
            "text": docs[idx],
            "source": metas[idx] if idx < len(metas) else {}
        }
        for idx in range(len(docs))
    ]
    return {
        "summary": summary,          # short answer ⇒ UI header
        "snippets": snippets,        # context ⇒ collapsible panel
        "citations": [s["id"] for s in snippets]  # mapping for inline tags
    }
```

### Typical JSON sent to the UI

```json
{
  "summary": "Root cause: dependency scanner failed to reach the proxy. "
             "Set MAVEN_OPTS per [#1] and clear cache as in [#2].",
  "snippets": [
    {
      "id": 1,
      "text": "Scanner error SCAN-405 occurs when the corporate proxy ...",
      "source": "kb/scan/scan_405.md"
    },
    {
      "id": 2,
      "text": "Run `mvn dependency:purge-local-repository` after updating proxy ...",
      "source": "kb/maven/cache_clear.md"
    }
  ],
  "citations": [1, 2]
}
```

---

## UI / client rendering contract

| Layer             | Recommended UX                                                                                                                             |
| ----------------- | ------------------------------------------------------------------------------------------------------------------------------------------ |
| **Header**        | Show `summary` with superscript links ¹, ² that scroll / expand the matching snippet.                                                      |
| **Context panel** | A collapsible section listing each snippet (`text`, `source`). Provide “Open full doc” if you store the full file path or URL in `source`. |
| **Export / copy** | If users copy the summary, include citation numbers so they retain attribution.                                                            |

---

## Implementation cautions

* **Chunk size** – keep ≤1 500 chars so the response isn’t huge, but always include enough surrounding lines for readability.
* **Order snippets** – same order the retriever returned; don’t reorder or you’ll break the numbering in citations.
* **Don’t mutate the KB** – retrieval is read-only.  Only add to the KB when an answer is *accepted* (your `/train` endpoint).
* **Token leak** – if you ever pipe all snippets back into a second LLM pass, truncate or window them to avoid 128 K token blow-ups.

---

### Bottom line

Delivering **(summary + context + citations)** is exactly how serious RAG products ship today. Your design is correct; just return all three parts in a single JSON object and let the front-end decide how to lay them out.
